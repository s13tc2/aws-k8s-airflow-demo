name: k8s-Apply

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to run tests against'
        type: environment
        required: true

env:
  TERRAFORM_VERSION: '1.5.7'

jobs:

  infra:
    runs-on: ubuntu-latest
    outputs:
      airflow_repository: ${{ steps.apply.outputs.airflow_repository }}
      airflow_repository_url: ${{ steps.apply.outputs.airflow_repository_url }}
      kubernetes_cluster_name: ${{ steps.apply.outputs.kubernetes_cluster_name }}
      primary_region: ${{ steps.apply.outputs.primary_region }}
      console_role: ${{ steps.apply.outputs.console_role }}
      admin_group: ${{ steps.apply.outputs.admin_group }}
      alb_controller_role: ${{ steps.apply.outputs.alb_controller_role }}
      workload_identity_role: ${{ steps.apply.outputs.workload_identity_role }}
    environment:
      name: ${{ inputs.environment }}

    steps:
      - uses: actions/checkout@v3

      - id: setup
        name: Setup `terraform`
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - id: apply
        name: Terraform Apply
        env:
          AWS_ACCESS_KEY_ID: ${{ vars.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          BACKEND_BUCKET_NAME: ${{ vars.BUCKET_NAME }}
          BACKEND_REGION: ${{ vars.BUCKET_REGION }}
          BACKEND_KEY: ${{ vars.APPLICATION_NAME }}-${{ vars.ENVIRONMENT_NAME }}
        working-directory: ${{ vars.TERRAFORM_WORKING_DIRECTORY }}
        run: |
          terraform init \
            -backend-config='bucket='$BACKEND_BUCKET_NAME \
            -backend-config='region='$BACKEND_REGION \
            -backend-config="key=${{ vars.APPLICATION_NAME }}-${{ vars.ENVIRONMENT_NAME }}"

          terraform apply -target "random_shuffle.az" -auto-approve
          terraform apply -auto-approve

          kubernetes_cluster_name=$(terraform output -raw kubernetes_cluster_name)
          echo "kubernetes_cluster_name=$kubernetes_cluster_name" >> "$GITHUB_OUTPUT"

          primary_region=$(terraform output -raw primary_region)
          echo "primary_region=$primary_region" >> "$GITHUB_OUTPUT"

          console_role=$(terraform output -raw console_role_arn)
          echo "console_role=$console_role" >> "$GITHUB_OUTPUT"

          alb_controller_role=$(terraform output -raw alb_controller_role)
          echo "alb_controller_role=$alb_controller_role" >> "$GITHUB_OUTPUT"

          workload_identity_role=$(terraform output -raw workload_identity_role)
          echo "workload_identity_role=$workload_identity_role" >> "$GITHUB_OUTPUT"

          admin_group=$(terraform output -raw admin_group_arn)
          echo "admin_group=$admin_group" >> "$GITHUB_OUTPUT"

          airflow_repository=$(terraform output -raw airflow_repository)
          echo "airflow_repository=$airflow_repository" >> "$GITHUB_OUTPUT"

          airflow_repository_url=$(terraform output -raw airflow_repository_url)
          echo "airflow_repository_url=$airflow_repository_url" >> "$GITHUB_OUTPUT"

  k8s:
    runs-on: ubuntu-latest
    needs: infra

    environment:
      name: ${{ inputs.environment }}

    steps:
      - uses: actions/checkout@v3

      - id: setup
        name: Setup `terraform`
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ vars.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ needs.infra.outputs.primary_region }}

      - name: Log in to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Update kubeconfig for EKS Cluster
        run: |
          aws eks update-kubeconfig --name ${{ needs.infra.outputs.kubernetes_cluster_name }} --region ${{ needs.infra.outputs.primary_region }}
      
      - name: Get Pods Status
        run: |
          kubectl get pods -n app -o wide

      - name: Delete Existing Resources
        run: |
          kubectl delete deployment airflow-webserver -n app --ignore-not-found=true
          kubectl delete ingress airflow-webserver-ingress -n app --ignore-not-found=true
          kubectl delete service airflow-webserver-service -n app --ignore-not-found=true
          
          # Wait a few seconds to ensure resources are fully deleted
          sleep 10
      
      - name: List All Pods
        run: |
          kubectl get pods --all-namespaces -o wide

      - name: Debug Secret Provider Class Names
        run: |
          echo "Expected Secret Provider Class name:"
          terraform output secret_provider_class_name
          
          echo "Actual Secret Provider Classes in cluster:"
          kubectl get secretproviderclass -n app -o name

      - name: Debug Secret Provider
        run: |
          echo "Checking Secret Provider Class..."
          kubectl get secretproviderclass -n app
          
          echo "Checking Secret Provider Class Details..."
          kubectl get secretproviderclass airflow-portal-dev-secret-provider-class -n app -o yaml
          
          echo "Checking Secrets Store CSI Driver Logs..."
          kubectl logs -n kube-system -l app=secrets-store-csi-driver

       # Add these new debug steps here:
      - name: Debug Pod Status
        run: |
          echo "Checking pod status..."
          kubectl get pods -n app -l app=airflow-webserver
          
          echo "Checking pod details..."
          kubectl describe pod -n app -l app=airflow-webserver
          
          echo "Checking pod logs..."
          kubectl logs -n app -l app=airflow-webserver

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/
          kubectl version --client

      - name: Install Helm
        run: |
          curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3
          chmod +x get_helm.sh
          ./get_helm.sh
          helm version

      - name: Add Helm Repositories
        run: |
          helm repo add secrets-store-csi-driver https://kubernetes-sigs.github.io/secrets-store-csi-driver/charts
          helm repo add aws-secrets-store https://aws.github.io/secrets-store-csi-driver-provider-aws
          helm repo update

      # - name: Uninstall Secrets Store CSI Driver
      #   run: |
      #     helm uninstall csi-secrets-store --namespace kube-system

      # - name: Uninstall AWS Secrets Provider
      #   run: |
      #     helm uninstall secrets-provider-aws --namespace kube-system

      - name: Install/Upgrade Secrets Store CSI Driver
        run: |
          helm upgrade --install csi-secrets-store secrets-store-csi-driver/secrets-store-csi-driver \
            --namespace kube-system \
            --create-namespace \
            --set syncSecret.enabled=true \
            --set installCRDs=true

      - name: Install/Upgrade AWS Secrets Provider
        run: |
          helm upgrade --install secrets-provider-aws aws-secrets-store/secrets-store-csi-driver-provider-aws \
            --namespace kube-system
                
      - name: Wait for CRDs to be Established
        run: |
          kubectl wait --for=condition=established crd secretproviderclasses.secrets-store.csi.x-k8s.io --timeout=120s
          kubectl wait --for=condition=established crd secretproviderclasspodstatuses.secrets-store.csi.x-k8s.io --timeout=120s
        
      # - name: Delete Existing Resources
      #   run: |
      #     kubectl delete deployment airflow-webserver -n app --ignore-not-found=true
      #     kubectl delete ingress airflow-webserver-ingress -n app --ignore-not-found=true
      #     kubectl delete service airflow-webserver-service -n app --ignore-not-found=true
          
      #     # Wait a few seconds to ensure resources are fully deleted
      #     sleep 10

      - id: Apply
        name: Terraform Apply
        env:
          AWS_ACCESS_KEY_ID: ${{ vars.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ needs.infra.outputs.primary_region }}
          AWS_DEFAULT_REGION: ${{ needs.infra.outputs.primary_region }}
          BACKEND_BUCKET_NAME: ${{ vars.BUCKET_NAME }}
          BACKEND_REGION: ${{ vars.BUCKET_REGION }}
          BACKEND_KEY: ${{ vars.APPLICATION_NAME }}-${{ vars.ENVIRONMENT_NAME }}-k8s
          TF_VAR_application_name: ${{ vars.APPLICATION_NAME }}
          TF_VAR_environment_name: ${{ vars.ENVIRONMENT_NAME }}
          TF_VAR_cluster_name: ${{ needs.infra.outputs.kubernetes_cluster_name }}
          TF_VAR_primary_region: ${{ needs.infra.outputs.primary_region }}
          TF_VAR_alb_controller_role: ${{ needs.infra.outputs.alb_controller_role }}
          TF_VAR_workload_identity_role: ${{ needs.infra.outputs.workload_identity_role }}
          TF_VAR_secret_name: ${{ vars.APPLICATION_NAME }}-${{ vars.ENVIRONMENT_NAME }}-connection-string
          TF_VAR_secret_key: ${{ secrets.DB_CONNECTION_STRING_KEY }}
          TF_VAR_k8s_namespace: ${{ env.K8S_NAMESPACE }}
          TF_VAR_ingress_controller_namespace: ${{ env.INGRESS_CONTROLLER_NAMESPACE }}
          TF_VAR_airflow_repository: ${{ needs.infra.outputs.airflow_repository }}
          TF_VAR_airflow_repository_url: ${{ needs.infra.outputs.airflow_repository_url }}
          TF_VAR_airflow_connection_string: "postgresql+psycopg2://airflow:airflow@localhost:5432/airflow"  # Add this
          TF_VAR_airflow_portal_dev_fernet_key: "Q7c8Hy_FAiUKTwIxN7yWgr8ZL0uogBTitrMtLLpCFsY="  # Add this
        working-directory: ./src/terraform/k8s
        run: |
          terraform init \
            -backend-config='bucket='$BACKEND_BUCKET_NAME \
            -backend-config='region='$BACKEND_REGION \
            -backend-config="key=${{ vars.APPLICATION_NAME }}-${{ vars.ENVIRONMENT_NAME }}-k8s"
              
          terraform apply -auto-approve

          k8s_namespace=$(terraform output -raw k8s_namespace)
          echo "k8s_namespace=$k8s_namespace" >> "$GITHUB_OUTPUT"

      # Debugging Steps Start Here
      - name: Get Pods Status
        run: |
          kubectl get pods -n ${{ steps.Apply.outputs.k8s_namespace }} -o wide

      - name: Get Services
        run: |
          kubectl get services -n ${{ steps.Apply.outputs.k8s_namespace }}
      
      - name: Validate airflow Service Endpoints
        run: |
          kubectl get endpoints airflow-service -n ${{ steps.Apply.outputs.k8s_namespace }} || exit 1

      - name: Get Events
        run: |
          kubectl get events -n ${{ steps.Apply.outputs.k8s_namespace }} --sort-by='.lastTimestamp'

      - name: Get Application Pod Logs
        run: |
          for pod in $(kubectl get pods -n ${{ steps.Apply.outputs.k8s_namespace }} -l app=airflow -o jsonpath='{.items[*].metadata.name}'); do
            echo "Logs for airflow pod: $pod"
            kubectl logs $pod -n ${{ steps.Apply.outputs.k8s_namespace }}
          done
          for pod in $(kubectl get pods -n ${{ steps.Apply.outputs.k8s_namespace }} -l app=airflow -o jsonpath='{.items[*].metadata.name}'); do
            echo "Logs for airflow pod: $pod"
            kubectl logs $pod -n ${{ steps.Apply.outputs.k8s_namespace }}
          done

      - name: Setup eksctl
        run: |
          ARCH=amd64
          PLATFORM=$(uname -s)_$ARCH

          curl -sLO "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_$PLATFORM.tar.gz"
          curl -sL "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_checksums.txt" | grep $PLATFORM | sha256sum --check

          tar -xzf eksctl_$PLATFORM.tar.gz -C /tmp
          sudo mv /tmp/eksctl /usr/local/bin
          rm eksctl_$PLATFORM.tar.gz

          eksctl version

      - name: Test eksctl command
        run: |
          eksctl get clusters
          eksctl get iamidentitymapping --cluster ${{ needs.infra.outputs.kubernetes_cluster_name }} --region=${{ needs.infra.outputs.primary_region }}

          eksctl create iamidentitymapping \
            --cluster ${{ needs.infra.outputs.kubernetes_cluster_name }} \
            --region=${{ needs.infra.outputs.primary_region }} \
            --arn ${{ needs.infra.outputs.console_role }} \
            --group eks-console-dashboard-full-access-group \
            --no-duplicate-arns

          eksctl create iamidentitymapping \
            --cluster ${{ needs.infra.outputs.kubernetes_cluster_name }} \
            --region=${{ needs.infra.outputs.primary_region }} \
            --arn arn:aws:iam::312344499806:user/markti \
            --group eks-console-dashboard-restricted-access-group \
            --no-duplicate-arns
