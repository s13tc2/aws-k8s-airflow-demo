name: k8s-Apply

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to run tests against'
        type: environment
        required: true

env:
  TERRAFORM_VERSION: '1.5.7'

jobs:

  infra:
    runs-on: ubuntu-latest
    outputs:
      airflow_repository: ${{ steps.apply.outputs.airflow_repository }}
      airflow_repository_url: ${{ steps.apply.outputs.airflow_repository_url }}
      kubernetes_cluster_name: ${{ steps.apply.outputs.kubernetes_cluster_name }}
      primary_region: ${{ steps.apply.outputs.primary_region }}
      console_role: ${{ steps.apply.outputs.console_role }}
      admin_group: ${{ steps.apply.outputs.admin_group }}
      alb_controller_role: ${{ steps.apply.outputs.alb_controller_role }}
      workload_identity_role: ${{ steps.apply.outputs.workload_identity_role }}
    environment:
      name: ${{ inputs.environment }}

    steps:
      - uses: actions/checkout@v3

      - id: setup
        name: Setup `terraform`
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - id: apply
        name: Terraform Apply
        env:
          AWS_ACCESS_KEY_ID: ${{ vars.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          BACKEND_BUCKET_NAME: ${{ vars.BUCKET_NAME }}
          BACKEND_REGION: ${{ vars.BUCKET_REGION }}
          BACKEND_KEY: ${{ vars.APPLICATION_NAME }}-${{ vars.ENVIRONMENT_NAME }}
        working-directory: ${{ vars.TERRAFORM_WORKING_DIRECTORY }}
        run: |
          terraform init \
            -backend-config='bucket='$BACKEND_BUCKET_NAME \
            -backend-config='region='$BACKEND_REGION \
            -backend-config="key=${{ vars.APPLICATION_NAME }}-${{ vars.ENVIRONMENT_NAME }}"

          terraform apply -target "random_shuffle.az" -auto-approve
          terraform apply -auto-approve

          kubernetes_cluster_name=$(terraform output -raw kubernetes_cluster_name)
          echo "kubernetes_cluster_name=$kubernetes_cluster_name" >> "$GITHUB_OUTPUT"

          primary_region=$(terraform output -raw primary_region)
          echo "primary_region=$primary_region" >> "$GITHUB_OUTPUT"

          console_role=$(terraform output -raw console_role_arn)
          echo "console_role=$console_role" >> "$GITHUB_OUTPUT"

          alb_controller_role=$(terraform output -raw alb_controller_role)
          echo "alb_controller_role=$alb_controller_role" >> "$GITHUB_OUTPUT"

          workload_identity_role=$(terraform output -raw workload_identity_role)
          echo "workload_identity_role=$workload_identity_role" >> "$GITHUB_OUTPUT"

          admin_group=$(terraform output -raw admin_group_arn)
          echo "admin_group=$admin_group" >> "$GITHUB_OUTPUT"

          airflow_repository=$(terraform output -raw airflow_repository)
          echo "airflow_repository=$airflow_repository" >> "$GITHUB_OUTPUT"

          airflow_repository_url=$(terraform output -raw airflow_repository_url)
          echo "airflow_repository_url=$airflow_repository_url" >> "$GITHUB_OUTPUT"

  k8s:
    runs-on: ubuntu-latest
    needs: infra

    environment:
      name: ${{ inputs.environment }}

    steps:
      - uses: actions/checkout@v3

      - id: setup
        name: Setup `terraform`
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ vars.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ needs.infra.outputs.primary_region }}

      - name: Log in to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Update kubeconfig for EKS Cluster
        run: |
          aws eks update-kubeconfig --name ${{ needs.infra.outputs.kubernetes_cluster_name }} --region ${{ needs.infra.outputs.primary_region }}

      # - name: Clean and Verify Secret Provider Setup
      #   run: |
      #     echo "Deleting old pods..."
      #     kubectl delete pod -n app -l app=airflow-webserver --force --grace-period=0 || true
          
      #     echo "\nVerifying SecretProviderClass exists..."
      #     if ! kubectl get secretproviderclass -n app airflow-portal-dev-secret-provider-class; then
      #       echo "SecretProviderClass not found. Waiting for Terraform to create it..."
      #       # Wait for SecretProviderClass to be created (adjust timeout as needed)
      #       timeout=60
      #       while [ $timeout -gt 0 ] && ! kubectl get secretproviderclass -n app airflow-portal-dev-secret-provider-class; do
      #         sleep 5
      #         timeout=$((timeout-5))
      #         echo "Waiting for SecretProviderClass... ${timeout}s remaining"
      #       done
      #     fi
          
      #     echo "\nVerifying SecretProviderClass configuration..."
      #     kubectl get secretproviderclass -n app airflow-portal-dev-secret-provider-class -o yaml
          
      #     echo "\nRestarting deployment to pick up new configuration..."
      #     kubectl rollout restart deployment/airflow-webserver -n app
          
      #     echo "\nWaiting for deployment rollout..."
      #     kubectl rollout status deployment/airflow-webserver -n app --timeout=300s

      - name: Create SecretProviderClass
        run: |
          echo "Creating SecretProviderClass manifest..."
          cat << 'EOF' > secretproviderclass.yaml
          apiVersion: secrets-store.csi.x-k8s.io/v1
          kind: SecretProviderClass
          metadata:
            name: airflow-portal-dev-secret-provider-class
            namespace: app
          spec:
            provider: aws
            parameters:
              objects: |
                - objectName: "airflow-portal-dev-connection-string"
                  objectType: "secretsmanager"
                  objectData:
                    - key: "connection"
                      objectAlias: "airflow-portal-dev-connection-string"
                - objectName: "airflow-portal-dev-fernet-key"
                  objectType: "secretsmanager"
                  objectData:
                    - key: "fernet_key"
                      objectAlias: "airflow-portal-dev-fernet-key"
            secretObjects:
              - data:
                  - key: connection
                    objectName: "airflow-portal-dev-connection-string"
                secretName: airflow-portal-dev-connection-string
                type: Opaque
              - data:
                  - key: fernet_key
                    objectName: "airflow-portal-dev-fernet-key"
                secretName: airflow-portal-dev-fernet-key
                type: Opaque
          EOF

          echo "Applying SecretProviderClass..."
          kubectl apply -f secretproviderclass.yaml

          echo "Verifying SecretProviderClass was created..."
          kubectl get secretproviderclass -n app

      - name: Restart Airflow Deployment
        run: |
          echo "Restarting deployment..."
          kubectl rollout restart deployment/airflow-webserver -n app
          
          echo "Waiting for rollout to complete..."
          kubectl rollout status deployment/airflow-webserver -n app --timeout=300s

      - name: Verify Setup
        run: |
          echo "Checking pod status..."
          kubectl get pods -n app -l app=airflow-webserver
          
          echo "\nChecking SecretProviderClass..."
          kubectl get secretproviderclass -n app -o yaml
          
          echo "\nChecking Kubernetes secrets..."
          kubectl get secrets -n app
          
          echo "\nChecking pod description..."
          kubectl describe pod -n app -l app=airflow-webserver
          
          echo "\nChecking CSI driver logs..."
          kubectl logs -n kube-system -l app=secrets-store-csi-driver --tail=50

      - name: Debug Status
        run: |
          echo "Checking pod status..."
          kubectl get pods -n app -l app=airflow-webserver
          
          echo "\nChecking pod description..."
          kubectl describe pod -n app -l app=airflow-webserver
          
          echo "\nChecking latest events..."
          kubectl get events -n app --sort-by='.lastTimestamp' | tail -n 20

      # - name: Debug Secrets
      #   run: |
      #     echo "Checking AWS Secrets Manager..."
      #     aws secretsmanager list-secrets | grep airflow-portal-dev
          
      #     echo "\nGetting AWS Secret Values..."
      #     aws secretsmanager get-secret-value --secret-id airflow-portal-dev-connection-string
      #     aws secretsmanager get-secret-value --secret-id airflow-portal-dev-fernet-key
          
      #     echo "\nChecking Kubernetes Secrets..."
      #     kubectl get secrets -n app
          
      #     echo "\nDescribing Kubernetes Secrets..."
      #     kubectl describe secret airflow-portal-dev-connection-string -n app
      #     kubectl describe secret airflow-portal-dev-fernet-key -n app
          
      #     echo "\nChecking Secret Provider Class..."
      #     kubectl get secretproviderclass -n app -o yaml
          
      #     echo "\nChecking CSI Driver Status..."
      #     kubectl get pods -n kube-system -l app=secrets-store-csi-driver
      #     kubectl logs -n kube-system -l app=secrets-store-csi-driver --tail=100

      # - name: Clean Up and Recreate Secrets
      #   run: |
      #     echo "Deleting existing SecretProviderClass..."
      #     kubectl delete secretproviderclass -n app airflow-portal-dev-secret-provider-class || true
          
      #     echo "Deleting existing Kubernetes secrets..."
      #     kubectl delete secret -n app airflow-portal-dev-connection-string || true
      #     kubectl delete secret -n app airflow-portal-dev-fernet-key || true
          
      #     echo "Deleting pods to force recreation..."
      #     kubectl delete pod -n app -l app=airflow-webserver --force --grace-period=0 || true
          
      #     echo "Waiting for new pod to be created..."
      #     kubectl wait --for=condition=ready pod -l app=airflow-webserver -n app --timeout=300s

      # - name: Verify Secret Setup
      #   run: |
      #     echo "Checking SecretProviderClass..."
      #     kubectl get secretproviderclass -n app
          
      #     echo "\nChecking Kubernetes secrets..."
      #     kubectl get secrets -n app
          
      #     echo "\nChecking pod status..."
      #     kubectl get pods -n app -l app=airflow-webserver
          
      #     echo "\nChecking pod events..."
      #     kubectl get events -n app --sort-by='.lastTimestamp' | grep airflow-webserver

      # - name: Check CSI Driver Logs
      #   if: ${{ failure() }}
      #   run: |
      #     echo "CSI Driver Logs..."
      #     kubectl logs -n kube-system -l app=secrets-store-csi-driver --tail=100

      # - name: Check AWS Secrets
      #   run: |
      #     echo "Checking AWS Secrets Manager..."
      #     aws secretsmanager list-secrets | grep airflow-portal-dev


      # - name: Debug Secret Provider Class
      #   run: |
      #     echo "Checking Secret Provider Class configuration..."
      #     kubectl get secretproviderclass airflow-portal-dev-secret-provider-class -n app -o yaml
      
      - name: Get Pods Status
        run: |
          kubectl get pods -n app -o wide

      # - name: Delete Existing Resources
      #   run: |
      #     kubectl delete deployment airflow-webserver -n app --ignore-not-found=true
      #     kubectl delete ingress airflow-webserver-ingress -n app --ignore-not-found=true
      #     kubectl delete service airflow-webserver-service -n app --ignore-not-found=true
          
      #     # Wait a few seconds to ensure resources are fully deleted
      #     sleep 10
      
      - name: List All Pods
        run: |
          kubectl get pods --all-namespaces -o wide

      - name: Debug Container Config Error
        run: |
          echo "Pod Description:"
          kubectl describe pod -n app -l app=airflow-webserver      
          echo "\nPod Events:"
          kubectl get events -n app --sort-by='.lastTimestamp' | grep airflow-webserver
          
          echo "\nContainer Logs (if any):"
          kubectl logs -n app -l app=airflow-webserver --all-containers=true --previous      
          echo "\nDeployment Configuration:"
          kubectl get deployment -n app airflow-webserver -o yaml

      - name: Debug Secret Provider Class Names
        run: |
          echo "Expected Secret Provider Class name:"
          terraform output secret_provider_class_name
          
          echo "Actual Secret Provider Classes in cluster:"
          kubectl get secretproviderclass -n app -o name

      - name: Debug Secret Provider
        run: |
          echo "Checking Secret Provider Class..."
          kubectl get secretproviderclass -n app
          
          echo "Checking Secret Provider Class Details..."
          kubectl get secretproviderclass airflow-portal-dev-secret-provider-class -n app -o yaml
          
          echo "Checking Secrets Store CSI Driver Logs..."
          kubectl logs -n kube-system -l app=secrets-store-csi-driver
          

      - name: Get Pods Status
        run: |
          kubectl get pods -n app -o wide

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/
          kubectl version --client

      - name: Install Helm
        run: |
          curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3
          chmod +x get_helm.sh
          ./get_helm.sh
          helm version

      - name: Add Helm Repositories
        run: |
          helm repo add secrets-store-csi-driver https://kubernetes-sigs.github.io/secrets-store-csi-driver/charts
          helm repo add aws-secrets-store https://aws.github.io/secrets-store-csi-driver-provider-aws
          helm repo update

      # - name: Uninstall Secrets Store CSI Driver
      #   run: |
      #     helm uninstall csi-secrets-store --namespace kube-system

      # - name: Uninstall AWS Secrets Provider
      #   run: |
      #     helm uninstall secrets-provider-aws --namespace kube-system

      - name: Install/Upgrade Secrets Store CSI Driver
        run: |
          helm upgrade --install csi-secrets-store secrets-store-csi-driver/secrets-store-csi-driver \
            --namespace kube-system \
            --create-namespace \
            --set syncSecret.enabled=true \
            --set installCRDs=true

      - name: Install/Upgrade AWS Secrets Provider
        run: |
          helm upgrade --install secrets-provider-aws aws-secrets-store/secrets-store-csi-driver-provider-aws \
            --namespace kube-system
                
      - name: Wait for CRDs to be Established
        run: |
          kubectl wait --for=condition=established crd secretproviderclasses.secrets-store.csi.x-k8s.io --timeout=120s
          kubectl wait --for=condition=established crd secretproviderclasspodstatuses.secrets-store.csi.x-k8s.io --timeout=120s
        
      - name: Delete Existing Resources
        run: |
          kubectl delete deployment airflow-webserver -n app --ignore-not-found=true
          kubectl delete ingress airflow-webserver-ingress -n app --ignore-not-found=true
          kubectl delete service airflow-webserver-service -n app --ignore-not-found=true
          
          # Wait a few seconds to ensure resources are fully deleted
          sleep 10

      - id: Apply
        name: Terraform Apply
        env:
          AWS_ACCESS_KEY_ID: ${{ vars.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ needs.infra.outputs.primary_region }}
          AWS_DEFAULT_REGION: ${{ needs.infra.outputs.primary_region }}
          BACKEND_BUCKET_NAME: ${{ vars.BUCKET_NAME }}
          BACKEND_REGION: ${{ vars.BUCKET_REGION }}
          BACKEND_KEY: ${{ vars.APPLICATION_NAME }}-${{ vars.ENVIRONMENT_NAME }}-k8s
          TF_VAR_application_name: ${{ vars.APPLICATION_NAME }}
          TF_VAR_environment_name: ${{ vars.ENVIRONMENT_NAME }}
          TF_VAR_cluster_name: ${{ needs.infra.outputs.kubernetes_cluster_name }}
          TF_VAR_primary_region: ${{ needs.infra.outputs.primary_region }}
          TF_VAR_alb_controller_role: ${{ needs.infra.outputs.alb_controller_role }}
          TF_VAR_workload_identity_role: ${{ needs.infra.outputs.workload_identity_role }}
          TF_VAR_secret_name: ${{ vars.APPLICATION_NAME }}-${{ vars.ENVIRONMENT_NAME }}-connection-string
          TF_VAR_secret_key: ${{ secrets.DB_CONNECTION_STRING_KEY }}
          TF_VAR_k8s_namespace: ${{ env.K8S_NAMESPACE }}
          TF_VAR_ingress_controller_namespace: ${{ env.INGRESS_CONTROLLER_NAMESPACE }}
          TF_VAR_airflow_repository: ${{ needs.infra.outputs.airflow_repository }}
          TF_VAR_airflow_repository_url: ${{ needs.infra.outputs.airflow_repository_url }}
          TF_VAR_airflow_connection_string: "postgresql+psycopg2://airflow:airflow@localhost:5432/airflow"  # Add this
        working-directory: ./src/terraform/k8s
        run: |
          terraform init \
            -backend-config='bucket='$BACKEND_BUCKET_NAME \
            -backend-config='region='$BACKEND_REGION \
            -backend-config="key=${{ vars.APPLICATION_NAME }}-${{ vars.ENVIRONMENT_NAME }}-k8s"
              
          terraform apply -auto-approve

          k8s_namespace=$(terraform output -raw k8s_namespace)
          echo "k8s_namespace=$k8s_namespace" >> "$GITHUB_OUTPUT"

      # Debugging Steps Start Here
      - name: Get Pods Status
        run: |
          kubectl get pods -n ${{ steps.Apply.outputs.k8s_namespace }} -o wide

      - name: Get Services
        run: |
          kubectl get services -n ${{ steps.Apply.outputs.k8s_namespace }}
      
      - name: Validate airflow Service Endpoints
        run: |
          kubectl get endpoints airflow-service -n ${{ steps.Apply.outputs.k8s_namespace }} || exit 1

      - name: Get Events
        run: |
          kubectl get events -n ${{ steps.Apply.outputs.k8s_namespace }} --sort-by='.lastTimestamp'

      - name: Get Application Pod Logs
        run: |
          for pod in $(kubectl get pods -n ${{ steps.Apply.outputs.k8s_namespace }} -l app=airflow -o jsonpath='{.items[*].metadata.name}'); do
            echo "Logs for airflow pod: $pod"
            kubectl logs $pod -n ${{ steps.Apply.outputs.k8s_namespace }}
          done
          for pod in $(kubectl get pods -n ${{ steps.Apply.outputs.k8s_namespace }} -l app=airflow -o jsonpath='{.items[*].metadata.name}'); do
            echo "Logs for airflow pod: $pod"
            kubectl logs $pod -n ${{ steps.Apply.outputs.k8s_namespace }}
          done

      - name: Setup eksctl
        run: |
          ARCH=amd64
          PLATFORM=$(uname -s)_$ARCH

          curl -sLO "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_$PLATFORM.tar.gz"
          curl -sL "https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_checksums.txt" | grep $PLATFORM | sha256sum --check

          tar -xzf eksctl_$PLATFORM.tar.gz -C /tmp
          sudo mv /tmp/eksctl /usr/local/bin
          rm eksctl_$PLATFORM.tar.gz

          eksctl version

      - name: Test eksctl command
        run: |
          eksctl get clusters
          eksctl get iamidentitymapping --cluster ${{ needs.infra.outputs.kubernetes_cluster_name }} --region=${{ needs.infra.outputs.primary_region }}

          eksctl create iamidentitymapping \
            --cluster ${{ needs.infra.outputs.kubernetes_cluster_name }} \
            --region=${{ needs.infra.outputs.primary_region }} \
            --arn ${{ needs.infra.outputs.console_role }} \
            --group eks-console-dashboard-full-access-group \
            --no-duplicate-arns

          eksctl create iamidentitymapping \
            --cluster ${{ needs.infra.outputs.kubernetes_cluster_name }} \
            --region=${{ needs.infra.outputs.primary_region }} \
            --arn arn:aws:iam::312344499806:user/markti \
            --group eks-console-dashboard-restricted-access-group \
            --no-duplicate-arns
